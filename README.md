# Stock market bot

## Installation (ubuntu)
1. Clone the repository
   ```bash
   git clone https://github.com/lpiekarski/SP2137.git
   cd SP2137
   ```
2. Install python
   ```bash
   apt-get update
   apt-get install -y python3 python3-venv
   ```
3. Create python virtual environment
   ```bash
   python3 -m venv venv --upgrade-deps
   ```
4. Install required python dependencies
   ```bash
   ./venv/bin/python3 -m pip install -r docker/files/requirements.txt
   ```

## Creating and Evaluating Models
1. Create a new `[model_name].py` file inside `/model/predictors` directory.
2. Copy the content of `/model/predictors/template.py` into your file.
3. Implement `train(X, y)` and `predict(X)` methods for your model.
4. Method `train(X, y)` should fit the model to the given dataset and store the result using `commons.drive`
5. Method `predict(X)` should return the model's prediction for a given input `X`
6. After finishing the implementation run the following command to evaluate and submit the evaluation results to neptune: 
    ```bash
    python3 bot.py evaluate --model=[model_name] --dataset=validate.csv --NEPTUNE_API_KEY=[neptune api token]
    ```

## Examples
1. Run tests:
   ```bash
   python3 bot.py test
   ```
2. Evaluate [model] using [dataset] (without saving results to neptune):
   ```bash
   python3 bot.py evaluate --model=[model] --dataset=[dataset]
   ```
3. Generate the output using [model] for given input [dataset] and save the results in [output] file:
    ```bash
    python3 bot.py predict --model=[model] --dataset=[dataset] --output=[output] 
    ```

## Repository Contents
- Github configuration (in `/.github`)
  - Contains directory `/.github/workflows` with github actions definition
- Data Collector (in `/collector`)
  - Collects all the necessary data for models
  - Exposes `/collector/collect.py` script that can be used to save data for the last or target hour onto target cloud location
  - Saved data contains at least `Date`, `Open`, `High`, `Low`, `Close` features, but also many more technical indicators
  - Features in saved data need not be normalized or standardized
- Commons (in `/commons`)
  - A technical module containing code that is reused across multiple modules
- Data (in `/data`)
  - Precomputed datasets stored using git-lfs
- Docker (in `/docker`)
  - Files needed for running bot using docker
- Evaluator (in `/evaluator`)
  - Evaluates the Model based on the predictions generated for test dataset in a way that the results can be compared with different models/runs of the same adjusted model
  - Exposes `/evaluator/evaluate.py` script that evaluates the Model and uploads results to Neptune
- Model (in `/model`)
  - Uses the data generated by Data Collector to create and store a prediction model
  - Exposes `/model/train.py` script that can be used to train the model on specified dataset and store the resulting model parameters
  - Exposes `/model/predict.py` script that generates model predictions for the specified dataset
- Testing (in `/testing`)
  - Test runner module containing script `/testing/test.py` that runs tests
- Trader (in `/trader`)
  - Trade using `/trader/trade.py` connecting through chosen broker API, perform decision based on command options or the result from Model
- Bot (in `/bot.py`)
  - CLI that bridges scripts exposed by modules into one command line tool